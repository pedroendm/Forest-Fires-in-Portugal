---
title: "Forest Fires in Portugal"
author:
  - "Pedro Mota"
  - "Tatiana Araújo"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/00mot/Desktop/DM1/Forest-Fires-in-Portugal")
```

# Introduction
Forest fires are a very important issue that negatively affects climate change. Typically, the causes of forest fires are those oversights, accidents and negligence committed by individuals, intentional acts and natural causes. The latter is the root cause for only a minority of the fires.
Their harmful impacts and effects on ecosystems can be major ones. Among them, we can mention the disappearance of native species,  the increase in levels of carbon dioxide in the atmosphere, the earth’s nutrients destroyed by the ashes, and the massive loss of wildlife. 
Data mining techniques can help in the prediction of the cause of the fire and, thus, better support the decision of taking preventive measures in order to avoid tragedy. In effect, this can play a major role in resource allocation, mitigation and recovery efforts. 
The ICFN - Nature and Forest Conservation Institute has the record of the list of forest fires that occurred in Portugal for several years. For each fire, there is information such as the site, the alert date/hour, the extinction date/hour, the affected area and the cause type (intentional, natural, negligent, rekindling or unknown).

The goal of this practical assignment is to build a machine learning model to predict the cause type of a forest fire: intentional or non-intentional.

For all the analysis, we used the language R and some of its packages from the CRAN, which we will load now:
```{r Library importation,warning=FALSE,message=FALSE}
library(tidyverse)
library(dlookr)
library(lubridate)
library(VIM)
library(rnoaa)
library(cowplot)
library(caret)
library(naivebayes)
library(rpart)
library(rpart.plot)
library(adabag)
library(ranger)
library(xgboost)
```

# Data Importation
Read the .csv file, containing the training data, as a tibble.
``` {r Data Importation, message=FALSE}
ds <- as_tibble(read_csv("fires_train.csv", na = c("-", "NA")))
#ds <- as_tibble(read_csv("fires_test.csv", na = c("-", "NA")))
glimpse(ds)
```
One can see that, the columns *id*, *intentional_cause* and *origin* are wrongly typed. In order to do fix this, we convert them to their correct types:
```{r Type conversion}
ds$id <- as.integer(ds$id)
ds$intentional_cause <- as.factor(ds$intentional_cause)
ds$origin <- as.factor(ds$origin)
```

# Data clean-up and pre-processing
Before we start the classification task, it's very important that we access the quality of our data, since poor data quality poses several challenges to the effective data analysis.

We started by looking for **missing values** and **duplicate data**.
In order to do that, we used the package *dlookr*.
```{r Overview}
overview(ds)
```
As one can see, there's no duplicate data, but there are a lot of missing values.
So we went finding which columns have missing values and how many values are missing, per attribute:
```{r Checking NAs,warning=FALSE,message=FALSE}
ds %>% select(find_na(.)) %>% diagnose()
```

From this diagnose, we can see that only the features *region*, *extinction_date*, *extinction_hour*, *firstInterv_date*, *firstInterv_hour* and *alert_source* have missing values. 

In particular, the column *alert_source* is all missing values, so we can immediately drop it:
```{r Removing alert_source}
ds <- select(ds, -alert_source)
```

Regarding the feature *region*, which is the one with more missing values (1206 in total), we don't need to worry about imputating the data, since we think, for our analysis, the information given by the *region* is too much broader. The same analysis is applied to the attributes *municipality* and *parish*, but, in both of them, the information in them is too specific. Also, we have the attributes *lat* and *lon*, which completely determines the location of the fire. Hence, we just kept the *district* attribute, which is in a sweet spot between specificity and vagueness.
```{r Removing region district municipality and parish}
ds <- select(ds, -c(region, municipality))
```

Concerning the variable *district*, we went finding which districts and how many are there, in our data set.
```{r}
distinct(data.frame(ds$district))
```

As we can see, there are 19 different districts, but, two of them ("Viana do Castelo" and "Viana Do Castelo") refer to the same district ("Viana do Castelo"), due to capitalization. So we normalized all cases with "Viana Do Castelo" to "Viana do Castelo":
```{r}
ds$district[ds$district == "Viana Do Castelo"] = "Viana do Castelo"
ds$district <- as.factor(ds$district)
```

Regarding the *alert_data*, *extinction_date* and *firstInterv_date* datetime attributes, we assumed that the time field is wrong and we substituted them by the attributes *alert_hour*, *extinction_hour* and *firstInterv_hour* and we called these new attributes *alert_datetime*, *extinction_datetime* and *firstInterv_datetime*, respectively.
```{r Fixing datetime attributes}
ds$alert_date = as.Date(ds$alert_date)
ds$extinction_date = as.Date(ds$extinction_date)
ds$firstInterv_date = as.Date(ds$firstInterv_date)

ds <- mutate(ds, alert_datetime = with(ds, ymd(alert_date) + hms(alert_hour)))
ds <- mutate(ds, extinction_datetime = with(ds, ymd(extinction_date) + hms(extinction_hour)))
ds <- mutate(ds, firstInterv_datetime = with(ds, ymd(firstInterv_date) + hms(firstInterv_hour)))

ds <- select(ds, -c(alert_date, alert_hour, extinction_date, extinction_hour, firstInterv_date, firstInterv_hour))
```

There are some cases with missing values for the extinction and first intervention datetimes, that we'll later imputate.

After this, we've found that the attribute *village_veget_area* and *total_area* are redundant, since they are just the sum of the feature *village_area* and *vegetation_area* and the the sum of the feature *village_area*, *vegetation_area* and *farming_area*, respectively, so we may drop them too. 
```{r Removing village_veget_area and total_area, echo=FALSE}
ds <- select(ds, -c(village_veget_area, total_area))
```

Regarding the attributes *lat* and *lon*, the latitude and longitude coordinates of the location of the fire, respectively, they are represented as characters, which isn't optimal for comparisons purposes. We could separate, for the latitude and longitude, the degrees, minutes and seconds measures and then convert them into numeric values, making a total of 6 features to represent the coordinates. Having 6 features representing the coordinates seemed exaggerated and we want to avoid the curse of high-dimensionality, so we look into other ways of representing the coordinates.

- The first idea was to convert the coordinates into a 3D coordinate space, where we would only have 3 features. Also, in the 3D coordinate space, close points are also close in reality, unlike in the coordinate system, where two extreme values can, actually, be very close together.

- The second idea was to convert the coordinates into a decimal representation. In this case, we have just 2 features to represent the coordinates and it's already in the form that will need later, in order to get the temperatures.

With this in mind and since, in our case, we are only working with latitudes and longitudes within Portugal, which means there no extreme coordinates that are very close in reality, we the choosed the decimal representation.

```{r coordinate_to_decimal function}
coordinate_to_decimal <- function(coordinate) {
  num = "(([0-9]+\\.[0-9]+)|([0-9]+))" # Regexp for integer and real numbers
  
  # Extract the numbers from the coordinate
  # Note that parsed_coordinate[1] is the degrees of the coordinate, parsed_coordinate[2] the minutes and parsed_coordinate[3] the seconds.
  parsed_coordinate <- as.double(str_extract_all(coordinate, num, simplify=TRUE)) 
  
  # Convert the coordinates to a decimal representation
  return (parsed_coordinate[1] + parsed_coordinate[2]/60 + parsed_coordinate[3]/3600)
}
coordinate_to_decimal = Vectorize(coordinate_to_decimal)

ds = mutate(ds, lat = coordinate_to_decimal(lat), lon = -1 * coordinate_to_decimal(lon))
```

Also, we've noticed that we have now missing values for the *lon* attribute. We suspected that was because of some strange values that couldn't be parsed with the function *str_extract_all*, from the package *stringr*, so we went finding them. 

```{r Looking for NAs again}
ds[is.na(ds$lon),]
```

Only 3 observations weren't rightful parsed, which correspond to the IDs 2522, 6817 and 8690. Looking in the original data set, they have the following values for the *lon* attribute, respectively: 0.29930555555555555, 0.36041666666666666 and 0.31319444444444444. Looking at the values, they seem to already in a decimal representation. But, with further analysis as we will show after, we found this values to be outliers. 
```{r Imputating NAs}
ds <- mutate(ds, alert_datetime=as.integer(alert_datetime), extinction_datetime=as.integer(extinction_datetime), firstInterv_datetime=as.integer(firstInterv_datetime))
ds <- as_tibble(kNN(ds, k=10)) %>% select(-ends_with("_imp"))

ds <- mutate(ds, alert_datetime       = as_datetime(alert_datetime), 
                 extinction_datetime  = as_datetime(extinction_datetime), 
                 firstInterv_datetime = as_datetime(firstInterv_datetime))
find_na(ds)
```

Finally, we checked if there are outliers. Namely regarding the *lat* and *lon* attributes, as one can see in the boxplots below. We considered a value to be an outlier if it's out of the range [1st Quartile - 1.5\*IQR, 3st Quartile + 1.5\*IQR]. 
```{r Boxplot for the lat and lon attribute}
lon_boxplot <- ggplot(ds) + geom_boxplot(aes(x = "Longitude", y=lon))
lat_boxplot <- ggplot(ds) + geom_boxplot(aes(x = "Latitude", y=lat))

plot_grid(lon_boxplot, lat_boxplot, labels = "AUTO")
```

We went further checking, for all numeric attributes, how many outliers are there: 
```{r Checking outliers}
ds %>% summarize(across(c(where(is.numeric), -id), ~length(boxplot(., plot=FALSE)$out)))
```

We just removed the outliers regarding the *lat* and *lon* attributes:
```{r Remove outliers from lat and lon attributes}
lat_outliers <- boxplot.stats(ds$lat)$out
lon_outliers <- boxplot.stats(ds$lon)$out

ds$lat[ds$lat %in% c(lat_outliers)] = NA
ds$lon[ds$lon %in% c(lon_outliers)] = NA
```


```{r}
ds <- as_tibble(kNN(ds, variable = c("lat", "lon"), dist_var=c("district", "parish"), k=8)) %>% select(-ends_with("_imp"))
ds <- select(ds, -parish)
```

<!--
We didn't remove the outliers from the other features, since we think that they aren't noise, as in the *lat* and *lon*, but informative to our prediction task.
```{r Temp and Prcp}
source("./getTemperatureNOAA.R")

#Add Temperatures and Precipitation
add_new_values <- function(ds){
  for(i in 1:length(ds$lat)) {
    print(i)
    nearby_stations = get_nearby_stations(ds$district[i],ds$lat[i], ds$lon[i])
    ds$max_temp[i] = add_temp_max(nearby_stations, as_date( ds$alert_datetime[i]))
    ds$prcp[i] = add_prcp(nearby_stations,  as_date(ds$alert_datetime[i]))
    if(i == nrow(ds))
      break
  }
  return(ds)
}
ds <- add_new_values(ds)
```
-->

```{r}
maxTemp = read_csv("train_maxTemp.csv")
prcp = read_csv("train_prcp.csv")

ds = merge(ds, maxTemp, by = "id")
ds = merge(ds, prcp, by = "id")

rm(maxTemp, prcp)
```

Having almost fixed all data quality problems with the original data set, we tried to use our domain knowledge of the data to create new features, using the original ones, hoping that they will capture new important information much more efficiently than the original features, which will help us solving the problem.

These new features are:

- ****: which is a factor attribute, having the values *morning*, *afternoon*, *evening* and *night*.

- **season**: which is a factor attribute, having the values *winter*, *spring*, *summer* and *autumn*.

We think these new attributes are helpful, since they may explain the origin of some natural causes, thus helping distinguish the cause of the fire, that is, our target variable.

For both of the new attributes, we made the assumption that the datetime given in the *alert_datetime* is a good approximation of the datetime of the starting of the fire, since a fire is, usually, immediately noticed.

```{r getSeason function}
ds <- mutate(ds, weekday = as.factor(weekdays(alert_datetime)))
```

And for the *season* attribute:
```{r month function}
ds <- mutate(ds, month = as.integer(month(alert_datetime)))
```

```{r hour function}
ds <- mutate(ds, hour = as.integer(hour(alert_datetime)))
```

Finally, regarding the *extinction_datetime* and the *firstInterv_datetime*, we think they can provide relevant information, but not as they are. That is, it's irrelevant the datetime by itself, but the difference, in minutes, within them, may be useful. So we created the *time_combating* and *time_till_firstInterv* attributes, which are the time, in minutes, spent combating the fire and the time, in minutes, for the first intervation, respectively.
Our hope is that there is some correlation between this new attributes and the target variable.
```{r getting timediffs}
ds <- mutate(ds, burning_time = as.double(difftime(extinction_datetime, alert_datetime, units="mins")))
ds$burning_time[ds$burning_time <= 0] = NA

ds <- as_tibble(kNN(ds, k=10)) %>% select(-ends_with("_imp"))

ds <- select(ds, -c(alert_datetime, extinction_datetime, firstInterv_datetime))
```


Relatively to the data cleaning and pre-processing, we are done. Regarding the normalization of the values, vital to some methods, that will be done after the exploratory analysis.

A final glimpse:
```{r Final glimpse}
ds = relocate(ds, intentional_cause, .after = last_col())
glimpse(ds)
```

# Data exploratory analysis
```{r}
#ggplot(ds, aes(x = season)) + geom_bar() + ggtitle("Fire distribution by season.")
```
```{r}
#ggplot(ds, aes(x = part_of_day)) + geom_bar() + ggtitle("Fire distribution by part of day")
```

```{r}
#ggplot(ds, aes(x=lon, y =lat)) + geom_point(aes(color=origin)) + ggtitle("Types of fires by latitude and longitude") + xlab("Longitude") + ylab("Latitude")
```


# Predictive modelling

We'll now start, finally, the predictive modelling.

Firstly, we will try the k-Nearest Neighboors:
1) KNN
```{r KNN}
fit <- train(intentional_cause ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = seq(5, 30, by = 2)),
             trControl  = trainControl(method  = "cv", number = 10),
             metric     = "Accuracy",
             preProc    = c("center", "scale"),
             data       = ds)
fit
```


```{r Data split}

```

2) Naive Bayes
```{r NB}
# nb.model <- naive_bayes(intentional_cause ~ ., data = ds_train, laplace=1)
# nb.preds <- predict(nb.model, ds_test)
# nb.confM <- confusionMatrix(ds_test_intentional_cause, nb.preds)
# nb.confM
```

3) DT
```{r}
# treeDs <- rpart(intentional_cause ~ ., ds)
# rpart.plot(treeDs)
```

```{r}
# treeDs$variable.importance
# #treeDs$cptable
```

4) Ensemble approaches
```{r}
ds = ds2

# 1st alternative
ds <- mutate(ds, burned_area = village_area + vegetation_area + farming_area)
ds <- select(ds, -c(village_area, vegetation_area, farming_area))

# 2nd alternative
ds <- mutate(ds, human_burned_area = village_area+farming_area, non_human_burned_area = vegetation_area)
ds <- select(ds, -c(village_area, vegetation_area, farming_area))

ds <- select(ds, -c(origin))

set.seed(42)
inTrain <- createDataPartition(y = ds$intentional_cause, p = 0.7, list = FALSE)
ds_train <- ds %>% dplyr::slice(inTrain)
ds_test <- ds %>% dplyr::slice(-inTrain)
```

4.1) Bagging
```{r Bagging}
#TODO: Fix this one. Taking a long time to construct the model
m <- bagging(intentional_cause ~ ., ds_train, mfinal = 5, control = rpart.control(maxdepth = 3), par=TRUE)
preds <- predict(m, ds_test)
confusionMatrix(as.factor(preds$class), ds_test_intentional_cause)
```

4.1) Random Forests
```{r Random Forests}
best_ntree= 0
best_mtry = 0
best_accuracy = 0

for (ntree in c(500, 750, 1000, 1250, 1500, 1750, 2000, 2250)) {
 for (mtry in c(2:(ncol(ds_train)-3))) {
   m <- ranger(intentional_cause ~ ., 
            data=select(ds_train, -id),
            num.trees = ntree, # 1800
            importance='impurity',
            #min.node.size = 4, 
            #probability = TRUE,
            #class.weights = costs,
            mtry=mtry) # 4
   
   preds <- predict(m, select(ds_test, -c(id,intentional_cause)))
   print(ntree) 
   print(mtry)
   accuracy=sum(as.integer(preds$predictions == ds_test$intentional_cause))/nrow(ds_test)
   print(accuracy)
   if (accuracy > best_accuracy) {
     best_accuracy = accuracy
     best_ntree = ntree
     best_mtry = mtry
   }
   print("--------------------")
 } 
}

m <- ranger(intentional_cause ~ ., 
            data=select(ds, -id),
            num.trees = 1800, # 1800
            importance='impurity',
            #min.node.size = 2, 
            probability = TRUE,
            mtry=ncol(ds)-2) # 4
   
preds <- predict(m, select(ds_submission, -c(id,intentional_cause, prcp)))

preds <- predict(m, select(ds, -id))

ds_submission = ds

preds$predictions = as.factor(as.integer(preds$predictions[1:nrow(ds_submission)] < 0.60))

confusionMatrix(preds$predictions, ds_test$intentional_cause)
```

```{r RF: Importance of variables}
m$importance
varImpPlot(m, main = "Feature Relevance Scores")
```

4.2) AdaBoost
```{r AdaBoost}
#TODO: Fix this one. Taking a long time to construct the model
#m <- boosting(intentional_cause ~ ., ds_train, mfinal = 5, control = rpart.control(maxdepth = 3))
#preds <- predict(m, ds_test)
#confusionMatrix(factor(preds$class), ds_test$diabetes)
```

4.3) Gradient Boost Machine
 TODO: not in any HO 

4.4) XGBoost
```{r}
m2 <- m
regressor=train(intentional_cause ~ ., data = ds_train, method = "xgbTree",trControl = trainControl("cv", number = 10),scale=T)
m <- xgboost(data = data.matrix(select(ds_train, -c(id,intentional_cause))),
             label = as.integer(ds_train$intentional_cause)-1,
             max.depth=4,
             #subsample=0.85,
             #colsample_bytree=0.8,
             eta=0.03,
             nrounds = 1100, #550
             #max_delta_step=0.9,
             scale_pos_weight=1.4,
             objective = "binary:logistic",
             eval_metric = "auc")

varImp(m)

preds <- predict(m, data.matrix(select(ds_test, -c(id,intentional_cause))), reshape=T)
preds <- predict(m, data.matrix(select(ds, -id)), reshape=T)
preds.class <- as.numeric(preds > 0.5)

ds <- mutate(ds, intentional_cause=factor(preds.class))
ds <- select(ds, c(id, intentional_cause))
confusionMatrix(factor(preds.class), factor(ds_test$intentional_cause))
```

```{r}
varImp <- xgb.importance(model=m)
xgb.plot.importance(varImp)
```

# Conclusion